{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import time\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, concatenate\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, Convolution1D, MaxPooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from nlp.glove import Glove\n",
    "from database.utils import get_train_test_data\n",
    "from evaluation.metrics import *\n",
    "from models.nn_models import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "train_test_data = get_train_test_data()\n",
    "X_train, y_train, X_test, y_test = get_train_test_data(merge=True)\n",
    "\n",
    "glove = Glove.load()\n",
    "w2v = glove.get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 75, 200)           3069000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 75, 100)           100400    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 3,174,603\n",
      "Trainable params: 105,603\n",
      "Non-trainable params: 3,069,000\n",
      "_________________________________________________________________\n",
      "Train on 8070 samples, validate on 2213 samples\n",
      "Epoch 1/5\n",
      "8070/8070 [==============================] - 28s 4ms/step - loss: 0.4200 - acc: 0.8395 - val_loss: 0.3338 - val_acc: 0.8787\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.792149 \n",
      "\n",
      "Epoch 2/5\n",
      "8070/8070 [==============================] - 24s 3ms/step - loss: 0.3053 - acc: 0.8741 - val_loss: 0.2565 - val_acc: 0.8928\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.872073 \n",
      "\n",
      "Epoch 3/5\n",
      "8070/8070 [==============================] - 23s 3ms/step - loss: 0.2263 - acc: 0.9018 - val_loss: 0.2162 - val_acc: 0.9044\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.900557 \n",
      "\n",
      "Epoch 4/5\n",
      "8070/8070 [==============================] - 23s 3ms/step - loss: 0.1875 - acc: 0.9147 - val_loss: 0.1961 - val_acc: 0.9089\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.915634 \n",
      "\n",
      "Epoch 5/5\n",
      "8070/8070 [==============================] - 24s 3ms/step - loss: 0.1686 - acc: 0.9230 - val_loss: 0.1879 - val_acc: 0.9141\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.922780 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed_size = 200 # how big is each word vector\n",
    "max_features = 20000 # dictionary size\n",
    "maxlen = 75 # max number of words in a tweet to use\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_train_test_data(merge=True)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train = pad_sequences(list_tokenized_train, maxlen)\n",
    "X_test = pad_sequences(list_tokenized_test, maxlen)\n",
    "\n",
    "embedding_matrix = glove.get_embedding_matrix(tokenizer, max_features, embed_size)\n",
    "model = get_lstm_model(embedding_matrix)\n",
    "#model = get_cnn_model(embedding_matrix)\n",
    "model.summary()\n",
    "ts = time.time()\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          epochs=5,\n",
    "          batch_size=256,\n",
    "          callbacks=[RocAucEvaluation(validation_data=(X_test, y_test)),\n",
    "                     TensorBoard(log_dir='./logs',\n",
    "                                 histogram_freq=0,\n",
    "                                 write_graph=True,\n",
    "                                 write_images=False)])\n",
    "te = time.time()\n",
    "train_time = te - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "y_scores = model.predict(X_test)\n",
    "te = time.time()\n",
    "predict_time = te - ts\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC for class 0: 0.96\n",
      "Precision for class 0: 0.72\n",
      "ROC AUC for class 1: 0.88\n",
      "Precision for class 1: 0.66\n",
      "ROC AUC for class 2: 0.98\n",
      "Precision for class 2: 0.69\n",
      "Average precision score, micro-averaged over all classes: 0.67\n",
      "Test score: 0.92\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>f1score</th>\n",
       "      <th>precision</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <td>0.746498</td>\n",
       "      <td>0.672772</td>\n",
       "      <td>0.641173</td>\n",
       "      <td>0.658377</td>\n",
       "      <td>3.921195</td>\n",
       "      <td>0.624845</td>\n",
       "      <td>0.955262</td>\n",
       "      <td>0.923353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy  avg_precision   f1score  precision  predict_time    recall  \\\n",
       "lstm  0.746498       0.672772  0.641173   0.658377      3.921195  0.624845   \n",
       "\n",
       "      specificity  test_roc_auc  \n",
       "lstm     0.955262      0.923353  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measures, _, _, _ = class_report_multilabel(y_test, y_scores)\n",
    "results['lstm'] = measures\n",
    "results['lstm']['predict_time'] = predict_time\n",
    "results['lstm']['train_time'] = train_time\n",
    "\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC for class 0: 0.97\n",
      "Precision for class 0: 0.77\n",
      "ROC AUC for class 1: 0.87\n",
      "Precision for class 1: 0.64\n",
      "ROC AUC for class 2: 0.97\n",
      "Precision for class 2: 0.75\n",
      "Average precision score, micro-averaged over all classes: 0.70\n",
      "Test score: 0.92\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>f1score</th>\n",
       "      <th>precision</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>0.765477</td>\n",
       "      <td>0.699341</td>\n",
       "      <td>0.630234</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>5.067211</td>\n",
       "      <td>0.551553</td>\n",
       "      <td>0.972575</td>\n",
       "      <td>0.920489</td>\n",
       "      <td>238.946852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  avg_precision   f1score  precision  predict_time    recall  \\\n",
       "cnn  0.765477       0.699341  0.630234   0.735099      5.067211  0.551553   \n",
       "\n",
       "     specificity  test_roc_auc  train_time  \n",
       "cnn     0.972575      0.920489  238.946852  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measures, _, _, _ = class_report_multilabel(y_test, y_scores)\n",
    "results['cnn'] = measures\n",
    "results['cnn']['predict_time'] = predict_time\n",
    "results['cnn']['train_time'] = train_time\n",
    "\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for Xr_train, y_train, Xr_test, y_test, indicator in train_test_data:\n",
    "    print(indicator)\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    \n",
    "    tokenizer.fit_on_texts(list(Xr_train))\n",
    "    list_tokenized_train = tokenizer.texts_to_sequences(Xr_train)\n",
    "    list_tokenized_test = tokenizer.texts_to_sequences(Xr_test)\n",
    "    X_train = pad_sequences(list_tokenized_train, maxlen)\n",
    "    X_test = pad_sequences(list_tokenized_test, maxlen)\n",
    "    \n",
    "    #embedding_matrix = get_embedding_matrix(max_features, tokenizer, w2v, embed_size)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #model = get_model(embedding_matrix)\n",
    "    #model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, \n",
    "    #      callbacks=[roc_callback(training_data=(X_train,\n",
    "    #                                             y_train),\n",
    "    #                              validation_data=(X_test, y_test))])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

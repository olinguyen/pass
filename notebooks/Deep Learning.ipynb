{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vmadmin/pass\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "\n",
    "from feature_extraction.features import *\n",
    "from feature_extraction.features import get_glove_w2v\n",
    "from database.utils import get_train_test_data\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "train_test_data = get_train_test_data()\n",
    "X_train, y_train, X_test, y_test = get_train_test_data(merge=True)\n",
    "\n",
    "w2v = get_glove_w2v()\n",
    "\n",
    "embed_size = 200 # how big is each word vector\n",
    "max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 75 # max number of words in a comment to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embedding_matrix(max_features, tokenizer, w2v, embed_size):\n",
    "    all_embs = np.stack(w2v.values())\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    emb_mean, emb_std    \n",
    "    \n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words + 1, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = w2v.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(embedding_matrix):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(input_dim=len(embedding_matrix), output_dim=embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(3, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_24 (Embedding)     (None, 75, 200)           3069000   \n",
      "_________________________________________________________________\n",
      "bidirectional_19 (Bidirectio (None, 75, 100)           100400    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 3,174,603\n",
      "Trainable params: 3,174,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8070 samples, validate on 2213 samples\n",
      "Epoch 1/5\n",
      "8070/8070 [==============================] - 85s 11ms/step - loss: 0.2471 - acc: 0.8942 - val_loss: 0.1896 - val_acc: 0.9128\n",
      "roc-auc: 0.9718 - roc-auc_val: 0.942                                                                                                    \n",
      "Epoch 2/5\n",
      "8070/8070 [==============================] - 76s 9ms/step - loss: 0.1410 - acc: 0.9372 - val_loss: 0.1806 - val_acc: 0.9156\n",
      "roc-auc: 0.9886 - roc-auc_val: 0.9496                                                                                                    \n",
      "Epoch 3/5\n",
      "8070/8070 [==============================] - 76s 9ms/step - loss: 0.1029 - acc: 0.9578 - val_loss: 0.1708 - val_acc: 0.9218\n",
      "roc-auc: 0.9965 - roc-auc_val: 0.9545                                                                                                    \n",
      "Epoch 4/5\n",
      "8070/8070 [==============================] - 77s 9ms/step - loss: 0.0680 - acc: 0.9733 - val_loss: 0.1996 - val_acc: 0.9178\n",
      "roc-auc: 0.999 - roc-auc_val: 0.9525                                                                                                    \n",
      "Epoch 5/5\n",
      "8070/8070 [==============================] - 76s 9ms/step - loss: 0.0444 - acc: 0.9841 - val_loss: 0.2035 - val_acc: 0.9262\n",
      "roc-auc: 0.9997 - roc-auc_val: 0.9513                                                                                                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb12f7fbcf8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train = pad_sequences(list_tokenized_train, maxlen)\n",
    "X_test = pad_sequences(list_tokenized_test, maxlen)\n",
    "\n",
    "embedding_matrix = get_embedding_matrix(max_features, tokenizer, w2v, embed_size)\n",
    "model = get_model(embedding_matrix)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, \n",
    "      callbacks=[roc_callback(training_data=(X_train,\n",
    "                                             y_train),\n",
    "                              validation_data=(X_test, y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.89925515e-06,   4.33312869e-03,   8.76744390e-01], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, 75, 200)           569000    \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 75, 100)           100400    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_16 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 674,501\n",
      "Trainable params: 674,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1146 samples, validate on 235 samples\n",
      "Epoch 1/5\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.6423 - acc: 0.6379 - val_loss: 0.7195 - val_acc: 0.4511\n",
      "roc-auc: 0.8186 - roc-auc_val: 0.6545                                                                                                    \n",
      "Epoch 2/5\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 0.5248 - acc: 0.7138 - val_loss: 0.7059 - val_acc: 0.5915\n",
      "roc-auc: 0.9136 - roc-auc_val: 0.6824                                                                                                    \n",
      "Epoch 3/5\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 0.3927 - acc: 0.8185 - val_loss: 0.5949 - val_acc: 0.6979\n",
      "roc-auc: 0.9558 - roc-auc_val: 0.7588                                                                                                    \n",
      "Epoch 4/5\n",
      "1146/1146 [==============================] - 10s 8ms/step - loss: 0.2867 - acc: 0.8778 - val_loss: 0.5677 - val_acc: 0.7234\n",
      "roc-auc: 0.9825 - roc-auc_val: 0.8326                                                                                                    \n",
      "Epoch 5/5\n",
      "1146/1146 [==============================] - 9s 8ms/step - loss: 0.2027 - acc: 0.9241 - val_loss: 0.5558 - val_acc: 0.7489\n",
      "roc-auc: 0.9921 - roc-auc_val: 0.8295                                                                                                    \n",
      "sedentary_behaviour\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_22 (Embedding)     (None, 75, 200)           2111800   \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 75, 100)           100400    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_17 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 2,217,301\n",
      "Trainable params: 2,217,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4294 samples, validate on 1363 samples\n",
      "Epoch 1/5\n",
      "4294/4294 [==============================] - 47s 11ms/step - loss: 0.5865 - acc: 0.6910 - val_loss: 0.4955 - val_acc: 0.7814\n",
      "roc-auc: 0.8682 - roc-auc_val: 0.7737                                                                                                    \n",
      "Epoch 2/5\n",
      "4294/4294 [==============================] - 39s 9ms/step - loss: 0.4246 - acc: 0.8125 - val_loss: 0.4810 - val_acc: 0.7792\n",
      "roc-auc: 0.945 - roc-auc_val: 0.8054                                                                                                    \n",
      "Epoch 3/5\n",
      "4294/4294 [==============================] - 39s 9ms/step - loss: 0.3066 - acc: 0.8696 - val_loss: 0.4818 - val_acc: 0.7909\n",
      "roc-auc: 0.9808 - roc-auc_val: 0.8122                                                                                                    \n",
      "Epoch 4/5\n",
      "4294/4294 [==============================] - 39s 9ms/step - loss: 0.2146 - acc: 0.9178 - val_loss: 0.5138 - val_acc: 0.7850\n",
      "roc-auc: 0.9945 - roc-auc_val: 0.8148                                                                                                    \n",
      "Epoch 5/5\n",
      "4294/4294 [==============================] - 39s 9ms/step - loss: 0.1244 - acc: 0.9548 - val_loss: 0.6147 - val_acc: 0.7770\n",
      "roc-auc: 0.9985 - roc-auc_val: 0.8071                                                                                                    \n",
      "physical_activity\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_23 (Embedding)     (None, 75, 200)           1441800   \n",
      "_________________________________________________________________\n",
      "bidirectional_18 (Bidirectio (None, 75, 100)           100400    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_18 (Glo (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,547,301\n",
      "Trainable params: 1,547,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2630 samples, validate on 615 samples\n",
      "Epoch 1/5\n",
      "2630/2630 [==============================] - 31s 12ms/step - loss: 0.5518 - acc: 0.7118 - val_loss: 0.4816 - val_acc: 0.7577\n",
      "roc-auc: 0.9103 - roc-auc_val: 0.8451                                                                                                    \n",
      "Epoch 2/5\n",
      "2630/2630 [==============================] - 23s 9ms/step - loss: 0.3581 - acc: 0.8384 - val_loss: 0.4112 - val_acc: 0.7935\n",
      "roc-auc: 0.9684 - roc-auc_val: 0.9026                                                                                                    \n",
      "Epoch 3/5\n",
      "2630/2630 [==============================] - 22s 9ms/step - loss: 0.2505 - acc: 0.8973 - val_loss: 0.4988 - val_acc: 0.7870\n",
      "roc-auc: 0.9865 - roc-auc_val: 0.9014                                                                                                    \n",
      "Epoch 4/5\n",
      "2630/2630 [==============================] - 23s 9ms/step - loss: 0.1850 - acc: 0.9278 - val_loss: 0.4481 - val_acc: 0.8163\n",
      "roc-auc: 0.9954 - roc-auc_val: 0.9047                                                                                                    \n",
      "Epoch 5/5\n",
      "2630/2630 [==============================] - 23s 9ms/step - loss: 0.1152 - acc: 0.9570 - val_loss: 0.5829 - val_acc: 0.7935\n",
      "roc-auc: 0.9986 - roc-auc_val: 0.9003                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "for Xr_train, y_train, Xr_test, y_test, indicator in train_test_data:\n",
    "    print(indicator)\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    \n",
    "    tokenizer.fit_on_texts(list(Xr_train))\n",
    "    list_tokenized_train = tokenizer.texts_to_sequences(Xr_train)\n",
    "    list_tokenized_test = tokenizer.texts_to_sequences(Xr_test)\n",
    "    X_train = pad_sequences(list_tokenized_train, maxlen)\n",
    "    X_test = pad_sequences(list_tokenized_test, maxlen)\n",
    "    \n",
    "    #embedding_matrix = get_embedding_matrix(max_features, tokenizer, w2v, embed_size)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    #model = get_model(embedding_matrix)\n",
    "    #model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, \n",
    "    #      callbacks=[roc_callback(training_data=(X_train,\n",
    "    #                                             y_train),\n",
    "    #                              validation_data=(X_test, y_test))])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
